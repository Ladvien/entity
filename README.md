# ğŸ§  Entity Framework

**Modular, voice-enabled agent framework with memory and plugin support.**

---

## ğŸ“Œ Overview

The Entity Framework is a developer-friendly platform for building multimodal, intelligent agents that feature:

- âœ… Centralized configuration via YAML
- âœ… Plugin system for custom tools
- âœ… Unified memory (chat + vector embeddings)
- âœ… Input/output adapter support (e.g., TTS, SST)

---

## ğŸ—‚ï¸ Project Structure

```
.
â”œâ”€â”€ cli.py                  # CLI entrypoint
â”œâ”€â”€ config.yml             # Central config file
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ core/               # Service registry and lifecycle
â”‚   â”œâ”€â”€ tools/              # Plugin tool system
â”‚   â”œâ”€â”€ memory/             # Unified memory access (chat + vector)
â”‚   â”œâ”€â”€ adapters/           # I/O adapters (TTS, SST, etc.)
â”‚   â””â”€â”€ agent/              # Agent logic (LLM wrapper, prompting)
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml          # Poetry setup
```

---

## âš™ï¸ Configuration-Driven Setup

The system is driven entirely by a single `config.yml`. It defines:

- **Database**: PostgreSQL + PGVector setup
- **LLM**: Base model and tuning parameters (via Ollama or similar)
- **Adapters**: Voice and audio settings

Example:

```yaml
database:
  host: "192.168.1.104"
  name: "memory"
  username: "${DB_USERNAME}"
  password: "${DB_PASSWORD}"
  db_schema: "entity"

adapters:
  tts:
    base_url: "http://localhost:8888"
    voice_name: "bf_emma"
    output_format: "wav"

  sst:
    enabled: false  # planned
    service: "whisper"
```

The config is parsed once at startup and registered globally using the `ServiceRegistry`.

---

## ğŸ§  Unified Memory System

All memory operations (chat history + embeddings) are routed through a unified memory layer. It is:

- Backed by PostgreSQL + PGVector
- Thread-aware
- Accessible by the agent and all tools
- Configured via `config.yml`

Memory operations support:
- Top-N similarity queries
- Full interaction logging
- Filtering by thread or type

---

## ğŸ”§ Plugin Tool Architecture

The plugin system allows developers to define **custom tools** that the agent can invoke automatically or manually. These tools are modular, easy to implement, and fully integrated with the memory system.

### ğŸ”Œ Plugin Directory

All custom tool plugins live in the top-level `plugins/` directory:

```
plugins/
â”œâ”€â”€ my_custom_tool.py        # Add your tool here
â”œâ”€â”€ another_tool.py
```

Each tool is a Python file that subclasses `BaseToolPlugin`, and is automatically discovered and loaded at runtime.

### ğŸ§° Writing a Tool

Create a new Python file under `src/tools/`, and define a subclass of `BaseToolPlugin`:

```python
# src/tools/my_tool.py
from src.tools.base_tool_plugin import BaseToolPlugin

class MyCustomTool(BaseToolPlugin):
    name = "my_custom_tool"
    description = "Returns a fixed response."

    def run(self, input: str) -> str:
        return "Here's your response!"
```

### ğŸ” Memory Access

If your tool needs to access memory (e.g., for retrieving context or storing results), use the service registry:

```python
from src.core.registry import get_service
from src.memory.system import MemorySystem

class RecallTool(BaseToolPlugin):
    name = "recall_tool"

    def run(self, input: str) -> str:
        memory: MemorySystem = get_service("memory")
        results = memory.search(input, top_k=3)
        return "\n".join(r.content for r in results)
```

### âš™ï¸ Auto-Registration

All tools are automatically loaded and registered at startup by `ToolManager`. No manual registration needed â€” just place your file in `src/tools/` and follow the base class structure.

---

## ğŸ”Š Adapter System

### âœ… Output Adapters
- **TTS (Text-to-Speech)** via REST-based services (e.g., Chatterbox, Kokoro)
- Controlled via the `adapters.tts` section of the config

### ğŸ”œ Planned Input Adapters
- **SST (Speech-to-Text)**: Whisper or other audio recognition tools
- Aimed at enabling full voice interaction

Adapters live in `src/adapters/` and are injected at runtime.

---

## ğŸš€ Execution Modes

Start the FastAPI web service:

```bash
poetry run python cli.py server
```

Run the CLI chat interface:

```bash
poetry run python cli.py client
```

Run both locally:

```bash
poetry run python cli.py both
```

---

## ğŸ§ª Developer Tips

- Add new tools in `src/tools/`
- Add new adapters in `src/adapters/`
- Modify LLM behavior via `src/agent/`
- Memory is shared, thread-safe, and searchable

---

## ğŸ“œ License

MIT â€” see `LICENSE` for details.
